* 推荐阅读：<br>
  * [ICCV2021/2019/2017 论文/代码/解读/直播合集](https://github.com/extreme-assistant/ICCV2021-Paper-Code-Interpretation)
  * [2020-2021年计算机视觉综述论文汇总](https://github.com/extreme-assistant/survey-computer-vision)
  * [国内外优秀的计算机视觉团队汇总](https://github.com/extreme-assistant/Awesome-CV-Team)
------

# CVPR2022最新信息及论文下载（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）

官网链接：http://CVPR2022.thecvf.com<br>
时间：2021年6月19日-6月24日<br>
论文接收公布时间：2022年3月2日<br>

相关问题：[如何评价 CVPR2022 的论文接收结果？](https://www.zhihu.com/question/519162597)<br>
相关报道：[CVPR 2022 接收结果出炉！录用 2067 篇，接收数量上升24%](https://mp.weixin.qq.com/s/hAWrCpili4CICJzKrQ8Sog)<br>


>update: <br>
>2022/3/3 [更新 19 篇](https://bbs.cvmart.net/articles/6149)<br>
>2022/3/4 [更新 29 篇](https://bbs.cvmart.net/articles/6151)<br>
>2022/3/7 [更新 17 篇](https://bbs.cvmart.net/articles/6158)

<br><br>

# 目录

[1. CVPR2022 接受论文/代码分方向汇总（更新中）](#1)<br>
[2. CVPR2022 Oral（更新中）](#2)<br>
[3. CVPR2022 论文解读汇总（更新中）](#3)<br>
[4. CVPR2022 极市论文分享](#4)<br>
[5. To do list](#5)<br>

<br>

<a name="1"/> 

# 1.CVPR2022接受论文/代码分方向整理(持续更新)


## 分类目录：

### [1. 检测](#detection)
* [2D目标检测(2D Object Detection)](#IOD)
* [视频目标检测(Video Object Detection)](#VOD)
* [3D目标检测(3D Object Detection)](#3DOD)
* [人物交互检测(HOI Detection)](#HOI)
* [伪装目标检测(Camouflaged Object Detection)](#COD)
* [旋转目标检测(Rotation Object Detection)](#ROD)
* [显著性目标检测(Saliency Object Detection)](#SOD)
* [图像异常检测(Anomally Detection in Image)](#ADI)
* [关键点检测(Keypoint Detection)](#KeypointDetection)
* [车道线检测(Lane Detection)](#LaneDetection)

### [2. 分割(Segmentation)](#Segmentation)
* [图像分割(Image Segmentation)](#ImageSegmentation)
* [全景分割(Panoptic Segmentation)](#PanopticSegmentation)
* [语义分割(Semantic Segmentation)](#SemanticSegmentation)
* [实例分割(Instance Segmentation)](#InstanceSegmentation)
* [超像素(Superpixel)](#Superpixel)
* [视频目标分割(Video Object Segmentation)](#VOS)
* [抠图(Matting)](#Matting)
* [密集预测(Dense Prediction)](#DensePrediction)

### [3. 图像处理(Image Processing)](#ImageProcessing)

* [超分辨率(Super Resolution)](#SuperResolution)
* [图像复原/图像增强/图像重建(Image Restoration/Image Reconstruction)](#ImageRestoration)
* [图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)](#ISR)
* [图像去噪/去模糊/去雨去雾(Image Denoising)](#ImageDenoising)
* [图像编辑/图像修复(Image Edit/Image Inpainting)](#ImageEdit)
* [图像翻译(Image Translation)](#ImageTranslation)
* [图像质量评估(Image Quality Assessment)](#IQA)
* [风格迁移(Style Transfer)](#StyleTransfer)

### [4. 估计(Estimation)](#Estimation)
* [姿态估计(Pose Estimation)](#HumanPoseEstimation)
* [手势估计(Gesture Estimation)](#GestureEstimation)
* [光流/位姿/运动估计(Flow/Pose/Motion Estimation)](#Flow/Pose/MotionEstimation)
* [深度估计(Depth Estimation)](#DepthEstimation)

### [5. 图像&视频检索/视频理解(Image&Video Retrieval/Video Understanding)](#ImageRetrieval)
* [行为识别/行为识别/动作识别/检测/分割(Action/Activity Recognition)](#ActionRecognition)
* [行人重识别/检测(Re-Identification/Detection)](#Re-Identification)
* [图像/视频字幕(Image/Video Caption)](#VideoCaption)

### [6. 人脸(Face)](#Face)
* [人脸识别/检测(Facial Recognition/Detection)](#FacialRecognition)
* [人脸生成/合成/重建/编辑(Face Generation/Face Synthesis/Face Reconstruction/Face Editing)](#FaceSynthesis)
* [人脸伪造/反欺骗(Face Forgery/Face Anti-Spoofing)](#FaceAnti-Spoofing)

### [7. 三维视觉(3D Vision)](#3DVision)
* [点云(Point Cloud)](#3DPC)
* [三维重建(3D Reconstruction)](#3DReconstruction)
* [场景重建/新视角合成(Novel View Synthesis)](#NeRF)

### [8. 目标跟踪(Object Tracking)](#ObjectTracking)

### [9. 医学影像(Medical Imaging)](#MedicalImaging)

### [10. 文本检测/识别(Text Detection/Recognition)](#TDR)

### [11. 遥感图像(Remote Sensing Image)](#RSI)

### [12. GAN/生成式/对抗式(GAN/Generative/Adversarial)](#GAN)

### [13. 图像生成/合成(Image Generation/Image Synthesis)](#IGIS)
* [视图合成(View Synthesis)](#ViewSynthesis)

### [14. 场景图(Scene Graph](#SG)
* [场景图生成(Scene Graph Generation)](#SGG)
* [场景图预测(Scene Graph Prediction)](#SGP)
* [场景图理解(Scene Graph Understanding)](#SGU)

### [15. 视觉定位(Visual Localization)](#VisualLocalization)

### [16. 视觉推理/视觉问答(Visual Reasoning/VQA)](#VisualReasoning)

### [17. 图像分类(Image Classification)](#ImageClassification)

### [18. 神经网络结构设计(Neural Network Structure Design)](#NNS)
* [CNN](#CNN)
* [Transformer](#Transformer)
* [图神经网络(GNN)](#GNN)
* [神经网络架构搜索(NAS)](#NAS)
* [MLP](#MLP)

### [19. 模型压缩(Model Compression)](#ModelCompression)
* [知识蒸馏(Knowledge Distillation)](#KnowledgeDistillation)
* [剪枝(Pruning)](#Pruning)
* [量化(Quantization)](#Quantization)

### [20. 模型训练/泛化(Model Training/Generalization)](#ModelTraining)
* [噪声标签(Noisy Label)](#NoisyLabel)
* [长尾分布(Long-Tailed Distribution)](#Long-Tailed)

### [21. 模型评估(Model Evaluation)](#ModelEvaluation)

### [22. 数据处理(Data Processing)](#DataProcessing)
* [数据增广(Data Augmentation)](#DataAugmentation)
* [表征学习(Representation Learning)](#RepresentationLearning)
* [归一化/正则化(Batch Normalization)](#BatchNormalization)
* [图像聚类(Image Clustering)](#ImageClustering)
* [图像压缩(Image Compression)](#ImageCompression)
* [异常检测(Anomaly Detection)](#AnomalyDetection)

### [23. 主动学习(Active Learning)](#ActiveLearning)

### [24. 小样本学习/零样本学习(Few-shot/Zero-shot Learning)](#Few-shotLearning)

### [25. 持续学习(Continual Learning/Life-long Learning)](#ContinualLearning)

### [26. 迁移学习/domain/自适应(Transfer Learning/Domain Adaptation)](#domain)

### [27. 度量学习(Metric Learning)](#MetricLearning)

### [28. 对比学习(Contrastive Learning)](#ContrastiveLearning)

### [29. 增量学习(Incremental Learning)](#IncrementalLearning)

### [30. 强化学习(Reinforcement Learning)](#RL)

### [31. 元学习(Meta Learning)](#MetaLearning)

### [32. 多模态学习(Multi-Modal Learning)](#MMLearning)
* [视听学习(Audio-visual Learning)](#Audio-VisualLearning)
* [视觉语言(Vision-language Representation Learning)](#VLRL)

### [33. 视觉预测(Vision-based Prediction)](#Vision-basedPrediction)

### [34. 数据集(Dataset)](#Dataset)

### [35. 机器人(Robotic)](#Robotic)

### [36. 自监督学习/半监督学习](#self-supervisedlearning)

### [暂无分类](#100)



<br><br>

<a name="detection"/> 

## 检测

<br>

<a name="IOD"/> 

### 图像目标检测(2D Object Detection)

[1] Localization Distillation for Dense Object Detection(密集对象检测的定位蒸馏)<br>
keywords: Bounding Box Regression, Localization Quality Estimation, Knowledge Distillation<br>
[paper](https://arxiv.org/abs/2102.12252) | [code](https://github.com/HikariTJU/LD)<br>
解读：[南开程明明团队和天大提出LD：目标检测的定位蒸馏](https://zhuanlan.zhihu.com/p/474955539)<br><br>

<br>


<a name="VOD"/> 

### 视频目标检测(Video Object Detection)

[1] Unsupervised Activity Segmentation by Joint Representation Learning and Online Clustering(通过联合表示学习和在线聚类进行无监督活动分割)<br>
[paper](https://arxiv.org/abs/2105.13353) | [video](https://www.youtube.com/watch?v=i4Fh_3nzzUI&t=12s)<br><br>

<br>

<a name="3DOD"/> 

### 3D目标检测(3D object detection)

[2] A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation(在全景分割的指导下，用于基于 LiDAR 的 3D 对象检测的多功能多视图框架)<br>
keywords: 3D Object Detection with Point-based Methods, 3D Object Detection with Grid-based Methods, Cluster-free 3D Panoptic Segmentation, CenterPoint 3D Object Detection<br>
[paper](https://arxiv.org/abs/2203.02133)<br><br>

[1] Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving(自动驾驶中用于单目 3D 目标检测的伪立体)<br>
keywords: Autonomous Driving, Monocular 3D Object Detection<br>
[paper](https://arxiv.org/abs/2203.02112) | [code](https://github.com/revisitq/Pseudo-Stereo-3D)<br><br>

<br>

<a name="HOI"/> 

### 人物交互检测(HOI Detection)

<br>

<a name="COD"/> 

### 伪装目标检测(Camouflaged Object Detection)

<br>

<a name="ROD"/> 

### 旋转目标检测(Rotation Object Detection)

<br>

<a name="SOD"/> 

### 显著性检测(Saliency Object Detection)

<br>

<a name="ADI"/> 

### 图像异常检测(Anomally Detection in Image)

<br>

<a name="KeypointDetection"/> 

### 关键点检测(Keypoint Detection)

<br>

<a name="LaneDetection"/> 

### 车道线检测(Lane Detection)

[1] Rethinking Efficient Lane Detection via Curve Modeling(通过曲线建模重新思考高效车道检测)<br>
keywords: Segmentation-based Lane Detection, Point Detection-based Lane Detection, Curve-based Lane Detection, autonomous driving<br>
[paper](https://arxiv.org/abs/2203.02431) | [code](https://github.com/voldemortX/pytorch-auto-drive)<br><br>

<br>

<a name="Segmentation"/> 


## 分割(Segmentation)

<br>

<a name="ImageSegmentation"/> 

### 图像分割(Image Segmentation)

<br>

<a name="PanopticSegmentation"/> 

### 全景分割(Panoptic Segmentation)

[1] Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation(弯曲现实：适应全景语义分割的失真感知Transformer)<br>
keywords: Semantic- and panoramic segmentation, Unsupervised domain adaptation, Transformer<br>
[paper](https://arxiv.org/abs/2203.01452) | [code](https://github.com/jamycheung/Trans4PASS)<br><br>

<br>

<a name="SemanticSegmentation"/> 

### 语义分割(Semantic Segmentation)

[2] ST++: Make Self-training Work Better for Semi-supervised Semantic Segmentation(让自我训练更好地用于半监督语义分割)<br>
keywords: Semi-supervised learning, Semantic segmentation, Uncertainty estimation<br>
[paper](https://arxiv.org/abs/2106.05095) | [code](https://github.com/LiheYoung/ST-PlusPlus)<br><br>

[1] Class Re-Activation Maps for Weakly-Supervised Semantic Segmentation(弱监督语义分割的类重新激活图)<br>
[paper](https://arxiv.org/pdf/2203.00962.pdf) | [code](https://github.com/zhaozhengChen/ReCAM)<br><br>

<br>

<a name="InstanceSegmentation"/> 

### 实例分割(Instance Segmentation)

[2] Efficient Video Instance Segmentation via Tracklet Query and Proposal(通过 Tracklet Query 和 Proposal 进行高效的视频实例分割)<br>
[paper](https://arxiv.org/abs/2203.01853)<br><br>

[1] SoftGroup for 3D Instance Segmentation on Point Clouds(用于点云上的 3D 实例分割)<br>
keywords: 3D Vision, Point Clouds, Instance Segmentation<br>
[paper](https://arxiv.org/abs/2203.01509) | [code](https://github.com/thangvubk/SoftGroup.git)<br><br>

<br>

<a name="Superpixel"/> 

### 超像素(Superpixel)

<br>

<a name="VOS"/> 

### 视频目标分割(Video Object Segmentation)

<br>

<a name="Matting"/> 

### 抠图(Matting)

<br>

<a name="DensePrediction"/> 

### 密集预测(Dense Prediction)

<br>

<a name="Estimation"/> 

## 估计(Estimation)

<a name="HumanPoseEstimation"/> 

### 姿态估计(Human Pose Estimation)

[2] Learning Local-Global Contextual Adaptation for Multi-Person Pose Estimation(学习用于多人姿势估计的局部-全局上下文适应)<br>
keywords:Top-Down Pose Estimation(从上至下姿态估计), Limb-based Grouping, Direct Regression<br><br>
[paper](https://arxiv.org/pdf/2109.03622.pdf)<br><br>

[1] MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video(用于视频中 3D 人体姿势估计的 Seq2seq 混合时空编码器)<br>
keywords：3D Human Pose Estimation, Transformer<br>
[paper](https://arxiv.org/pdf/2203.00859.pdf)<br><br>

<br>

<a name="GestureEstimation"/> 


### 手势估计(Gesture Estimation)

<br>

<a name="Flow/Pose/MotionEstimation"/> 

### 光流/位姿/运动估计(Optical Flow/Pose/Motion Estimation)

<br>

<a name="DepthEstimation"/> 

### 深度估计(Depth Estimation)

[5] ITSA: An Information-Theoretic Approach to Automatic Shortcut Avoidance and Domain Generalization in Stereo Matching Networks(立体匹配网络中自动避免捷径和域泛化的信息论方法)<br>
keywords: Learning-based Stereo Matching Networks, Single Domain Generalization, Shortcut Learning<br>
[paper](https://arxiv.org/pdf/2201.02263.pdf)<br><br>

[4] Attention Concatenation Volume for Accurate and Efficient Stereo Matching(用于精确和高效立体匹配的注意力连接体积)<br>
keywords: Stereo Matching, cost volume construction, cost aggregation<br>
[paper](https://arxiv.org/pdf/2203.02146.pdf)  | [code](https://github.com/gangweiX/ACVNet)<br><br>

[3] Occlusion-Aware Cost Constructor for Light Field Depth Estimation(光场深度估计的遮挡感知成本构造函数)<br>
[paper](https://arxiv.org/pdf/2203.01576.pdf) | [code](https://github.com/YingqianWang/OACC- Net)<br><br>

[2] NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation(用于单目深度估计的神经窗口全连接 CRF)<br>
keywords:  Neural CRFs for Monocular Depth<br>
[paper](https://arxiv.org/pdf/2203.01502.pdf)<br><br>

[1] OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion(通过几何感知融合进行 360 度单目深度估计)<br>
keywords: monocular depth estimation(单目深度估计),transformer<br>
[paper](https://arxiv.org/abs/2203.00838)<br><br>


<br>

<a name="ImageProcessing"/> 


## 图像处理(Image Processing)

<br>

<a name="SuperResolution"/> 

### 超分辨率(Super Resolution)

[1] HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging(光谱压缩成像的高分辨率双域学习)<br>
keywords: HSI Reconstruction, Self-Attention Mechanism,  Image Frequency Spectrum Analysis<br>
[paper](https://arxiv.org/pdf/2203.02149.pdf)<br><br>

<br>

<a name="ImageRestoration"/> 

###  图像复原/图像增强/图像重建(Image Restoration/Image Reconstruction)

[1] Event-based Video Reconstruction via Potential-assisted Spiking Neural Network(通过电位辅助尖峰神经网络进行基于事件的视频重建)<br>
[paper](https://arxiv.org/pdf/2201.10943.pdf)<br><br>

<br>


<a name="ISR"/> 

### 图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)

<br>



<a name="ImageDenoising"/> 

### 图像去噪/去模糊/去雨去雾(Image Denoising)

[1] E-CIR: Event-Enhanced Continuous Intensity Recovery(事件增强的连续强度恢复)<br>
keywords: Event-Enhanced Deblurring, Video Representation<br>
[paper](https://arxiv.org/abs/2203.01935) | [code](https://github.com/chensong1995/E-CIR)<br><br>

<br>

<a name="ImageEdit"/> 

### 图像编辑/图像修复(Image Edit/Inpainting)

[2] HairCLIP: Design Your Hair by Text and Reference Image(通过文本和参考图像设计你的头发)<br>
keywords: Language-Image Pre-Training (CLIP), Generative Adversarial Networks<br>
[paper](https://arxiv.org/abs/2112.05142) | [project](https://github.com/wty-ustc/HairCLIP)<br><br>

[1] Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding(增量transformer结构增强图像修复与掩蔽位置编码)<br>
keywords: Image Inpainting, Transformer, Image Generation<br><br>
[paper](https://arxiv.org/abs/2203.00867) | [code](https://github.com/DQiaole/ZITS_inpainting)<br><br>

<br>

<a name="ImageTranslation"/> 

### 图像翻译(Image Translation)

[1] Exploring Patch-wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks(探索图像到图像翻译任务中对比学习的补丁语义关系)<br>
keywords: image translation, knowledge transfer,Contrastive learning<br>
[paper](https://arxiv.org/pdf/2203.01532.pdf)<br><br>

<br>

<a name="IQA"/> 

### 图像质量评估(Image Quality Assessment)

<br>

<a name="StyleTransfer"/> 

### 风格迁移(Style Transfer)

[1] CLIPstyler: Image Style Transfer with a Single Text Condition(具有单一文本条件的图像风格转移)<br>
keywords: Style Transfer, Text-guided synthesis, Language-Image Pre-Training (CLIP)<br>
[paper](https://arxiv.org/abs/2112.00374)<br><br>


<br>

<a name="Face"/> 

## 人脸(Face)

<br>

<a name="FacialRecognition"/> 

### 人脸识别/检测(Facial Recognition/Detection)

[1] An Efficient Training Approach for Very Large Scale Face Recognition(一种有效的超大规模人脸识别训练方法)<br>
[paper](https://arxiv.org/pdf/2105.10375.pdf) | [code](https://github.com/tiandunx/FFC)<br><br>

<br>

<a name="FaceSynthesis"/> 

### 人脸生成/合成/重建/编辑(Face Generation/Face Synthesis/Face Reconstruction/Face Editing)

[1] Sparse to Dense Dynamic 3D Facial Expression Generation(稀疏到密集的动态 3D 面部表情生成)<br>
keywords: Facial expression generation, 4D face generation, 3D face modeling<br>
[paper](https://arxiv.org/pdf/2105.07463.pdf)<br><br>

<br>

<a name="FaceAnti-Spoofing"/> 

### 人脸伪造/反欺骗(Face Forgery/Face Anti-Spoofing)

[2] Voice-Face Homogeneity Tells Deepfake<br>
[paper](https://arxiv.org/abs/2203.02195) | [code](https://github.com/xaCheng1996/VFD)<br><br>

[1] Protecting Celebrities with Identity Consistency Transformer(使用身份一致性transformer保护名人)<br>
[paper](https://arxiv.org/abs/2203.01318)<br><br>


<br>

<a name="ObjectTracking"/> 

## 目标跟踪(Object Tracking)

[3] TCTrack: Temporal Contexts for Aerial Tracking(空中跟踪的时间上下文)<br>
[paper](https://arxiv.org/abs/2203.01885) | [code](https://github.com/vision4robotics/TCTrack)<br><br>

[2] Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds(超越 3D 连体跟踪：点云中 3D 单对象跟踪的以运动为中心的范式)<br>
keywords: Single Object Tracking, 3D Multi-object Tracking / Detection, Spatial-temporal Learning on Point Clouds<br>
[paper](https://arxiv.org/abs/2203.01730)<br><br>

[1] Correlation-Aware Deep Tracking(相关感知深度跟踪)<br>
[paper](https://arxiv.org/abs/2203.01666)<br><br>

<br>
<a name="ImageRetrieval"/> 

## 图像&视频检索/视频理解(Image&Video Retrieval/Video Understanding)

[1] BEVT: BERT Pretraining of Video Transformers(视频Transformer的 BERT 预训练)<br>
keywords: Video understanding, Vision transformers, Self-supervised representation learning, BERT pretraining<br>
[paper](https://arxiv.org/abs/2112.01529) | [code](https://github.com/xyzforever/BEVT)<br><br>



<a name="ActionRecognition"/> 

### 行为识别/动作识别/检测/分割/定位(Action/Activity Recognition)

[1] Colar: Effective and Efficient Online Action Detection by Consulting Exemplars(通过咨询示例进行有效且高效的在线动作检测)<br>
keywords:Online action detection(在线动作检测)<br>
[paper](https://arxiv.org/pdf/2203.01057.pdf)<br><br>

<a name="Re-Identification"/> 

### 行人重识别/检测(Re-Identification/Detection)



<a name="VideoCaption"/> 

### 图像/视频字幕(Image/Video Caption)

[1] X -Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning(使用 Transformer 进行 3D 密集字幕的跨模式知识迁移)
keywords：Image Captioning and Dense Captioning(图像字幕/密集字幕)；Knowledge distillation(知识蒸馏)；Transformer；3D Vision(三维视觉)<br>
[paper](https://arxiv.org/pdf/2203.00843.pdf)<br><br>


<a name="MedicalImaging"/> 

## 医学影像(Medical Imaging)

[1] Temporal Context Matters: Enhancing Single Image Prediction with Disease Progression Representations(时间上下文很重要：使用疾病进展表示增强单图像预测)<br>
keywords: Self-supervised Transformer, Temporal modeling of disease progression<br>
[paper](https://arxiv.org/abs/2203.01933)<br><br>


<a name="TDR"/> 


## 文本检测/识别(Text Detection/Recognition)



<a name="RSI"/> 

## 遥感图像(Remote Sensing Image)




<a name="GAN"/> 

## GAN/生成式/对抗式(GAN/Generative/Adversarial)

[1] Label-Only Model Inversion Attacks via Boundary Repulsion(通过边界排斥的仅标签模型反转攻击)<br>
[paper](https://arxiv.org/pdf/2203.01925.pdf)<br>


<br>

<a name="IGIS"/> 

## 图像生成/图像合成(Image Generation/Image Synthesis)

[4] 3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch Feature Swapping for Bodies and Faces(基于小批量特征交换的三维形状变化自动编码器潜在解纠缠)<br>
[paper](https://arxiv.org/pdf/2111.12448.pdf) | [code](https://github.com/simofoti/3DVAE-SwapDisentangled)<br><br>

[3] Interactive Image Synthesis with Panoptic Layout Generation(具有全景布局生成的交互式图像合成)<br>
[paper])(https://arxiv.org/abs/2203.02104)<br><br>

[2] Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values(极性采样：通过奇异值对预训练生成网络的质量和多样性控制)<br>
[paper](https://arxiv.org/abs/2203.01993) | [demo](http://bit.ly/polarity-demo-colab)<br><br>

[1] Autoregressive Image Generation using Residual Quantization(使用残差量化的自回归图像生成)<br>
[paper](https://arxiv.org/abs/2203.01941) | [code](https://github.com/kakaobrain/rq-vae-transformer)<br><br>

<br>

<a name="ViewSynthesis"/> 

### 视图合成(View Synthesis)



<br>

<a name="3DVision"/> 

## 三维视觉(3D Vision)

[1] X -Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning(使用 Transformer 进行 3D 密集字幕的跨模式知识迁移)
关键词：图像字幕/密集字幕；知识蒸馏；Transformer；三维视觉<br>
[paper](https://arxiv.org/pdf/2203.00843.pdf)<br><br>

<br>

<a name="3DPC"/> 

### 点云(Point Cloud)

[2] A Unified Query-based Paradigm for Point Cloud Understanding(一种基于统一查询的点云理解范式)<br>
[paper](https://arxiv.org/pdf/2203.01252.pdf)<br><br>

[1] CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding(用于 3D 点云理解的自监督跨模态对比学习)<br>
keywords: Self-Supervised Learning, Contrastive Learning, 3D Point Cloud, Representation Learning, Cross-Modal Learning<br>
[paper](https://arxiv.org/abs/2203.00680) | [code](http://github.com/MohamedAfham/CrossPoint)<br><br>

<br>


<a name="3DReconstruction"/> 

### 三维重建(3D Reconstruction)

[1] H4D: Human 4D Modeling by Learning Neural Compositional Representation(通过学习神经组合表示进行人体 4D 建模)<br>
keywords: 4D Representation(4D 表征),Human Body Estimation(人体姿态估计),Fine-grained Human Reconstruction(细粒度人体重建)<br><br>
[paper](https://arxiv.org/pdf/2203.01247.pdf)<br>

<a name="NeRF"/> 

### 场景重建/新视角合成(Novel View Synthesis)

[2] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields(文本和图像驱动的神经辐射场操作)<br>
keywords: NeRF,  Image Generation and Manipulation, Language-Image Pre-Training (CLIP)<br>
[paper](https://arxiv.org/abs/2112.05139) | [code](https://cassiepython.github.io/clipnerf/)<br><br>

[1] Point-NeRF: Point-based Neural Radiance Fields(基于点的神经辐射场)<br>
[paper](https://arxiv.org/pdf/2201.08845.pdf) | [code](https://github.com/Xharlie/pointnerf) | [project](https://xharlie.github.io/projects/project_sites/pointnerf/index.html)<br><br>

<a name="ModelCompression"/> 

## 模型压缩(Model Compression)

<br>

<a name="KnowledgeDistillation"/> 

### 知识蒸馏(Knowledge Distillation)

<a name="Pruning"/> 

### 剪枝(Pruning)

<a name="Quantization"/> 

### 量化(Quantization)



<br>

<a name="NNS"/> 

## 神经网络结构设计(Neural Network Structure Design)

[1] BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning(学习探索样本关系以进行鲁棒表征学习)<br>
keywords: sample relationship, data scarcity learning, Contrastive Self-Supervised Learning, long-tailed recognition, zero-shot learning, domain generalization, self-supervised learning<br>
[paper](https://arxiv.org/abs/2203.01522) | [code](https://github.com/zhihou7/BatchFormer)<br><br>

<br>

<a name="CNN"/> 

### CNN

[1] A ConvNet for the 2020s<br>
[paper](https://arxiv.org/abs/2201.03545) | [code](https://github.com/facebookresearch/ConvNeXt)<br>
解读：[“文艺复兴” ConvNet卷土重来，压过Transformer！FAIR重新设计纯卷积新架构](https://mp.weixin.qq.com/s/q-s_dV4-TCiVPMOTZKEgPQ)<br><br>

<br>

<a name="Transformer"/> 

### Transformer

[1] Mobile-Former: Bridging MobileNet and Transformer(连接 MobileNet 和 Transformer)<br>
keywords: Light-weight convolutional neural networks(轻量卷积神经网络),Combination of CNN and ViT<br>
[paper](https://arxiv.org/abs/2108.05895)<br><br>

<br>

<a name="GNN"/> 

### 图神经网络(GNN)

<br>

<a name="NAS"/> 

### 神经网络架构搜索(NAS)

[1] β-DARTS: Beta-Decay Regularization for Differentiable Architecture Search(可微架构搜索的 Beta-Decay 正则化)<br>
[paper](https://arxiv.org/abs/2203.01665)<br><br>

<a name="MLP"/> 

### MLP

[1] An Image Patch is a Wave: Quantum Inspired Vision MLP(图像补丁是波浪：量子启发的视觉 MLP)<br>
[paper](https://arxiv.org/abs/2111.12294) | [code](https://github.com/huawei-noah/CV-Backbones/tree/master/wavemlp_pytorch) | [code](https://gitee.com/mindspore/models/tree/master/research/cv/wave_mlp)<br><br>


<br>

<a name="DataProcessing"/> 

## 数据处理(Data Processing)

<a name="DataAugmentation"/> 

### 数据增广(Data Augmentation)

[1] 3D Common Corruptions and Data Augmentation(3D 常见损坏和数据增强)<br>
keywords: Data Augmentation, Image restoration, Photorealistic image synthesis<br>
[paper](https://arxiv.org/abs/2203.01441) | [projecr](https://3dcommoncorruptions.epfl.ch/)<br><br>

<br>

<a name="RepresentationLearning"/> 

### 表征学习(Representation Learning)



<br>

<a name="BatchNormalization"/> 

### 归一化/正则化(Batch Normalization)

<br>

<a name="ImageClustering"/> 

### 图像聚类(Image Clustering)

<br>


<a name="ImageCompression"/> 

### 图像压缩(Image Compression)

<br>

<a name="AnomalyDetection"/> 

### 异常检测(Anomaly Detection)

[1] Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection(用于异常检测的自监督预测卷积注意力块)(论文暂未上传)<br>
[paper](https://arxiv.org/abs/2111.09099) | [code](https://github.com/ristea/sspcab)<br><br>


<br>

<a name="ModelTraining"/> 

## 模型训练/泛化(Model Training/Generalization)



[3] CAFE: Learning to Condense Dataset by Aligning Features(通过对齐特征学习压缩数据集)<br>
keywords: dataset condensation, coreset selection, generative models<br>
[paper](https://arxiv.org/pdf/2203.01531.pdf) | [code](https://github.com/kaiwang960112/CAFE)<br><br>

[2] The Devil is in the Margin: Margin-based Label Smoothing for Network Calibration(魔鬼在边缘：用于网络校准的基于边缘的标签平滑)<br>
[paper](https://arxiv.org/abs/2111.15430) | [code](https://github.com/by-liu/MbLS)<br><br>

[1] DN-DETR: Accelerate DETR Training by Introducing Query DeNoising(通过引入查询去噪加速 DETR 训练)<br>
keywords: Detection Transformer<br>
[paper](https://arxiv.org/abs/2203.01305) | [code](https://github.com/FengLi-ust/DN-DETR)<br><br>

<br>

<a name="NoisyLabel"/> 

### 噪声标签(Noisy Label)



<br>

<a name="Long-Tailed"/> 

### 长尾分布(Long-Tailed Distribution)

[1] Targeted Supervised Contrastive Learning for Long-Tailed Recognition(用于长尾识别的有针对性的监督对比学习)<br>
keywords: Long-Tailed Recognition(长尾识别), Contrastive Learning(对比学习)<br>
[paper](https://arxiv.org/pdf/2111.13998.pdf)<br><br>

<br>

<a name="ModelEvaluation"/> 

## 模型评估(Model Evaluation)



<br>

<a name="MMLearning"/> 

## 多模态学习(Multi-Modal Learning)



<br>

<a name="Audio-VisualLearning"/> 

### 视听学习(Audio-visual Learning)


<br>

<a name="VLRL"/> 

### 视觉语言（Vision-language Representation Learning）

[3] HairCLIP: Design Your Hair by Text and Reference Image(通过文本和参考图像设计你的头发)<br>
keywords: Language-Image Pre-Training (CLIP), Generative Adversarial Networks<br>
[paper](https://arxiv.org/abs/2112.05142) | [project](https://github.com/wty-ustc/HairCLIP)<br><br>

[2] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields(文本和图像驱动的神经辐射场操作)<br>
keywords: NeRF,  Image Generation and Manipulation, Language-Image Pre-Training (CLIP)<br>
[paper](https://arxiv.org/abs/2112.05139) | [code](https://cassiepython.github.io/clipnerf/)<br><br>

[1] Vision-Language Pre-Training with Triple Contrastive Learning(三重对比学习的视觉语言预训练)<br>
keywords: Vision-language representation learning, Contrastive Learning
[paper](https://arxiv.org/abs/2202.10401) | [code](https://github.com/uta-smile/TCL;)<br><br>


<br>
<a name="Vision-basedPrediction"/> 

## 视觉预测(Vision-based Prediction)



<br>
<a name="Dataset"/> 

## 数据集(Dataset)



<br>

<a name="ActiveLearning"/> 

## 主动学习(Active Learning)



<br>

<a name="Few-shotLearning"/> 

## 小样本学习/零样本学习(Few-shot Learning/Zero-shot Learning)



<br>

<a name="ContinualLearning"/> 

## 持续学习(Continual Learning/Life-long Learning)

<br>

<a name="SG"/> 

## 场景图(Scene Graph)

<a name="SGG"/> 

### 场景图生成(Scene Graph Generation)

[1] Classification-Then-Grounding: Reformulating Video Scene Graphs as Temporal Bipartite Graphs(将视频场景图重新格式化为时间二分图)<br>
keywords: Video Scene Graph Generation, Transformer, Video Grounding<br> 
[paper](https://arxiv.org/abs/2112.04222) | [code](https://github.com/Dawn-LX/VidVRD-tracklets)<br><br>

<br>

<a name="SGP"/> 

### 场景图预测(Scene Graph Prediction)

<br>

<a name="SGU"/> 

### 场景图理解(Scene Graph Understanding)

<br>

<a name="VisualLocalization"/> 

## 视觉定位(Visual Localization)

<br>

<a name="VisualReasoning"/> 

## 视觉推理/视觉问答(Visual Reasoning/VQA)

<br>

<a name="ImageClassification"/> 

## 图像分类(Image Classification)

<br>

<a name="domain"/> 

## 迁移学习/domain/自适应(Transfer Learning/Domain Adaptation)

[1] Weakly Supervised Object Localization as Domain Adaption(作为域适应的弱监督对象定位)<br>
keywords: Weakly Supervised Object Localization(WSOL), Multi-instance learning based WSOL, Separated-structure based WSOL, Domain Adaption<br>
[paper](https://arxiv.org/abs/2203.01714) | [code](https://github.com/zh460045050/DA-WSOL_CVPR2022)<br><br>

<br>

<a name="MetricLearning"/> 

## 度量学习(Metric Learning)

[1] Enhancing Adversarial Robustness for Deep Metric Learning(增强深度度量学习的对抗鲁棒性)<br>
keywords: Adversarial Attack, Adversarial Defense, Deep Metric Learning<br>
[paper](https://arxiv.org/pdf/2203.01439.pdf)<br><br>

<br>

<a name="ContrastiveLearning"/> 

## 对比学习(Contrastive Learning)

[2] HCSC: Hierarchical Contrastive Selective Coding(分层对比选择性编码)<br>
keywords: Self-supervised Representation Learning, Deep Clustering, Contrastive Learning<br>
[paper](https://arxiv.org/abs/2202.00455) | [code](https://github.com/gyfastas/HCSC)<br><br>

[1] Crafting Better Contrastive Views for Siamese Representation Learning(为连体表示学习制作更好的对比视图)<br>
[paper](https://arxiv.org/pdf/2202.03278.pdf) | [code](https://github.com/xyupeng/ContrastiveCrop)<br><br>

<br>

<a name="IncrementalLearning"/> 

## 增量学习(Incremental Learning)

<br>

<a name="RL"/> 

## 强化学习(Reinforcement Learning)

<br>

<a name="MetaLearning"/> 

## 元学习(Meta Learning)

<br>

<a name="Robotic"/> 

## 机器人(Robotic)

[1] IFOR: Iterative Flow Minimization for Robotic Object Rearrangement(IFOR：机器人对象重排的迭代流最小化)<br>
[paper](https://arxiv.org/pdf/2202.00732.pdf) | [project](https://imankgoyal.github.io/ifor.html)<br><br>

<br>

<a name="self-supervisedlearning"/> 

## 自监督学习/半监督学习

[2] Class-Aware Contrastive Semi-Supervised Learning(类感知对比半监督学习)<br>
keywords: Semi-Supervised Learning, Self-Supervised Learning, Real-World Unlabeled Data Learning<br>
[paper](https://arxiv.org/abs/2203.02261)<br><br>

[1] A study on the distribution of social biases in self-supervised learning visual models(自监督学习视觉模型中social biases分布的研究)<br>
[paper](https://arxiv.org/pdf/2203.01854.pdf)<br><br>



<br><br>

<a name="100"/> 

## 暂无分类

[2] Do Explanations Explain? Model Knows Best(解释解释吗？ 模型最清楚)<br>
[paper](https://arxiv.org/abs/2203.02269)<br><br>

[1] PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence(PINA：从单个 RGB-D 视频序列中学习个性化的隐式神经化身)<br>
[paper](https://arxiv.org/abs/2203.01754) | [video](https://youtu.be/oGpKUuD54Qk) | [project](https://zj-dong.github.io/pina/)<br><br>

<br>

<br>

<a name="2"/> 


# 2. CVPR2022 Oral

<br>

<br>

<a name="3"/> 

# 3. CVPR2022 论文解读汇总




<br>

<a name="4"/> 

# 4. CVPR2022论文分享

<br>

<br>

<a name="5"/> 

# 5. To do list

* CVPR2022 Workshop
